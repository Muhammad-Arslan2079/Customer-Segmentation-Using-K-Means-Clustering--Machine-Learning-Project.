# -*- coding: utf-8 -*-
"""Customer Segmentation Using K-Means Clustering- Machine Learning Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yqm0hzQwMbumC8WZ3v67IxAhv2S1Hu26

**Importing the dependencies**
"""

import numpy as np # for numpy arrays
import pandas as pd # for dataframe creation and data analysis
import matplotlib.pyplot as plt # visualizations
import seaborn as sns # advance visualizations
from sklearn.cluster import KMeans  # kmeans clustering algorithm
import json # to read and write json format files
import os # to interact with operating system environment,creating folders, setting paths
from zipfile import ZipFile # to unzip compressed dataset downloaded from kaggle
from sklearn.preprocessing import LabelEncoder  # to encode features into numerical format

"""**Data Collection through Kaggle API and Analysis**"""

! pip install kaggle  # installing kaggle library to access datasets
kaggle_dictionary=json.load(open('/content/kaggle.json'))  # creating a varible and storing kaggle downloaded token that contain username and passkey by provideing file path, as key value pairs
os.environ['KAGGLE_USERNAME']= kaggle_dictionary['username']  # setting kaggle username as user name in variable with key value pairs
os.environ['KAGGLE_KEY']= kaggle_dictionary['key'] # setting key as key in variable
kaggle_dictionary.keys() # to check keys
#!/bin/bash
!kaggle datasets download vjchoudhary7/customer-segmentation-tutorial-in-python  # api command to download dataset

# unzip the compressed data
with ZipFile('/content/customer-segmentation-tutorial-in-python.zip') as zipped:
 zipped.extractall()

# loading data set and creating data frame
df=pd.read_csv('/content/Mall_Customers.csv')
df.head()

df.shape # number of rows and columns

df.info() # checking datatypes

df.isnull().sum() # checking missing values or null values

#encoded= LabelEncoder()
#df['Gender']=encoded.fit_transform(df['Gender'])
#print(df['Gender'])

x=df.iloc[:,[3,4]].values # storing 3rd and 4th index columns in variable x

print(x)

"""**Choosing the correct number of Clusters**

Using wcss- means - with in clusters sum of squares -  is basically a performance metrics to find the suitable number of clusters.It measure distance of each data point with its respective  centroid, then square it to avoid negatives and then take sum all scores,this will give wcss value,we get different wcss values for different number of clusters, and use elbow method that shows a sudden slow down which indicates best number of suitable clusters.
"""

wcss=[]
for i in range(1,11): # loop will run as clusters and generate within cluster score for each cluster
  kmeans= KMeans(n_clusters=i,init='k-means++',random_state=42) # parameters involved number of clusters,initiation method to select centeroids  randomly in start to compare data points.
  kmeans.fit(x) # training model  on data stored in x variable
  wcss.append(kmeans.inertia_)  # generating wcss score and appending in wcss variable

# plotting an elbow graph to find which cluster has minimum value
sns.set() # to set parameters including  figure dimensions
plt.plot(range(1,11),wcss) # range(1,11) will be display clusters on x axis and wcss score will be on y axis
plt.title('The Elbow Point Graph') # naming,title
plt.xlabel('Number of Clusters') # naming x axis
plt.ylabel('Wcss Score/Value')# naming y axis
plt.show() #to show plot

"""from visuals we can see that there are two sudden drops, 1 between 2 and 4 clusters and other between 4 and 6 clusters, we will use the optimum cluster as a cluster between 4 and 6, the reason for this is,we can see that after this drop there is not other sudden drop,
optimum cluster= 5

Training the K means Clustering Model
"""

kmeans= KMeans(n_clusters=5,init='k-means++',random_state=0) # this time not loop,exact 5 suitable clusters, random state for similar distribution across multiple systems
# each datapoint will be assigned to a specific cluster out 5 clusters based on similar annual income and spending score
# returning the label for each cluster
y= kmeans.fit_predict(x)# will fit on all values of x and predict a label/cluster number at a same time
print(y) # printing predicted labels

"""**Visualizing all the Clusters**"""

# plotting clusters
plt.figure(figsize=(8,8))
plt.scatter(x[y==0,0],x[y==0,1],s=20,c='green',label='cluster 1') # x[y==0,0] first 0 represents cluster number,means 1sr cluster at 0th index,2nd 0 represent first feature that is annual income,x[y==0,1] 0 represents cluster number at 0th index and 1 represent second feature at 1th index that is  spending score.
plt.scatter(x[y==1,0],x[y==1,1],s=20,c='red',label='cluster 2')
plt.scatter(x[y==2,0],x[y==2,1],s=20,c='blue',label='cluster 3')
plt.scatter(x[y==3,0],x[y==3,1],s=20,c='purple',label='cluster 4')
plt.scatter(x[y==4,0],x[y==4,1],s=20,c='yellow',label='cluster 5')
# plotting centeroid
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=100,c='black',label='centeroids') # s represent datapoint size,c represents color,label represents the name.

plt.title(' Clusters of Similar Datapoints')
plt.xlabel('Annual income')
plt.ylabel('Spending Score')
plt.show()

"""**Insights**

1.   People with small or less annual income ususally have high spending score or they spent more in mall compare to those with high annual income.
2.   People with high annual income mostly have low spending score or they spend less in mall as compare to those with low annual income
3. People with low annual income and high spending scores can be offered with gift cards,loyality cards etc

4. Group of people with low annual income and low spending score can be offered with discounts,packages,offers to attract them and generate more sales.
"""

